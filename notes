Diffusion Model : create cuda kernel fussed

[] -> Create Conv + ReLU + BatchNorm kernel	 	
[] -> Create a kernel for attention kernel. Trying to optimize it
-> Maybe a kernel for having the skip connection? I am thinking to have a kernel that will performe some reduction operations

[] -> MLP
[] -> GeGLu 

[] -> add dropout to layers !

[] -> Add activation to all of them

[] -> Kernel for skip conenction Conv
[] -> Kernel for VAEs . To compute stuff in the forward directly. Like taking the mean and computing stuff directly.
[] -> Kernel for having the thetas computed and maybe somehow save it on the gpu ? Like on the runtime till one signal save it


-> 2x faster than pytorch !


Convs : https://www.evl.uic.edu/sjames/cs525/final.html
https://leimao.github.io/blog/Neural-Network-Batch-Normalization-Fusion/


Project : What i want to achive is to create a diffusion model that is small, but also have the custom kernels and test them. 
          Implement papers related to diffusion models. 

          So the model will be small and custom convolutions. 

          Maybe create custom layers :D with functions that can interpolate between them .4



TODO : Diagram of the model ! 
